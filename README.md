# Store Analytics - Data Pipeline Practice Project

Este proyecto implementa una pipeline de datos completa para una tienda ficticia. Incluye scripts para generar datos sint칠ticos, poblar una base de datos PostgreSQL, ejecutar consultas anal칤ticas, visualizar los resultados y explorarlos de forma interactiva.

## Caracter칤sticas

- **Generaci칩n de Datos**: Crea datos falsos realistas para clientes, productos y ventas.
- **Persistencia de Datos**: Carga los datos generados en una base de datos PostgreSQL.
- **An치lisis de Datos**: Ejecuta consultas complejas para obtener informaci칩n de negocio, como los productos m치s vendidos y las tendencias de ventas.
- **Visualizaci칩n de Datos**: Genera gr치ficos informativos a partir de los datos analizados.
- **Exploraci칩n Interactiva**: Un Jupyter Notebook para an치lisis y visualizaci칩n en tiempo real.

---

## Prerrequisitos

Antes de comenzar, aseg칰rate de tener instalado lo siguiente:
- **Python 3.8+**
- **PostgreSQL**: Un servidor de base de datos PostgreSQL en funcionamiento.

---

## 丘뙖잺 Instalaci칩n y Configuraci칩n

Sigue estos pasos para poner en marcha el proyecto.

### 1. Clonar el Repositorio

```bash
git clone https://github.com/Breiner-Barrios/Store_Analytics_Data_Pipeline_Practice_Project.git
```

### 2. Crear y Activar un Entorno Virtual

Es una buena pr치ctica trabajar dentro de un entorno virtual para aislar las dependencias del proyecto.

### 3. Instalar Dependencias

Instala todas las librer칤as de Python necesarias.

```bash
pip install -r requirements.txt
```

### 3. Configurar la Base de Datos

**a. Crear las Tablas:**
Necesitas ejecutar el script SQL para crear el esquema y las tablas en tu base de datos. Puedes usar una herramienta como `psql`, DBeaver, o pgAdmin.

- Con칠ctate a tu servidor PostgreSQL.
- Ejecuta el contenido del archivo `database/script.sql`. Esto crear치 el esquema `store_analytics` y las tablas `customers`, `products` y `sales`.

**b. Configurar la Conexi칩n:**
Crea un archivo llamado `.env` en la ra칤z del proyecto. Puedes copiar el archivo `.env.example` como plantilla.

```bash
# Copia la plantilla (en Windows)
copy .env.example .env

# Copia la plantilla (en macOS/Linux)
cp .env.example .env
```

---

## 游 Uso del Proyecto (Poblar las Tablas)

El proceso para poblar la base de datos se divide en dos pasos:

### Paso 1: Generar los Archivos CSV

Ejecuta el script `mainwithout.py` para generar los datos de prueba. El script te pedir치 que introduzcas el n칰mero de registros que deseas para clientes, productos y ventas.

```bash
python mainwithout.py
```

Esto crear치 (o sobrescribir치) los archivos `customers.csv`, `products.csv` y `sales.csv` dentro de una carpeta `seeders/`.

### Paso 2: Cargar los Datos a la Base de Datos

Una vez que los archivos CSV est칠n listos, ejecuta el script `load_data.py` para cargarlos en tus tablas de PostgreSQL.

```bash
python load_data.py
```

El script leer치 los archivos de la carpeta `seeders/` y los insertar치 en el orden correcto para respetar las claves for치neas.

---

## 游늵 Ejecutar Consultas de An치lisis

Para ver los resultados de los an치lisis de datos (ej. productos m치s vendidos, tendencias mensuales), ejecuta el script `query_data.py`.

```bash
python query_data.py
```


## 游늳 Visualizar los Datos

Para generar los gr치ficos basados en los an치lisis (productos m치s vendidos, tendencia mensual, etc.), ejecuta el script `visualize_data.py`.

```bash
python visualize_data.py
```

## 游댧 An치lisis Interactivo con Jupyter Notebook

El archivo `query_data_notebook.ipynb` te permite explorar los datos y las funciones de consulta de forma interactiva. Es ideal para probar nuevas consultas o realizar an치lisis exploratorios sobre la marcha.

Para usarlo, aseg칰rate de tener Jupyter instalado (`pip install notebook`) y ejecuta el siguiente comando en tu terminal.

